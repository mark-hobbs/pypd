{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fa3f694-ca6c-47d9-8f97-3f7f44274974",
   "metadata": {},
   "source": [
    "# GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ffda115-a162-4e96-97d8-9c9ef0ebcd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ec94f4-ba7d-4b56-940e-3270d57975f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"Function '{func.__name__}' executed in {end - start:.4f} seconds\")\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78623c73-e4ee-43ca-8eb9-62d2dbdf87d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in Colab\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "    !pip install git+https://github.com/mark-hobbs/pypd.git\n",
    "    print(\"Package installed successfully\")\n",
    "    import pypd\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    import pypd\n",
    "\n",
    "    print(\"Not running in Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e3e419f-a756-4b07-bc85-702c907dea98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in Colab.\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "    try:\n",
    "        gpu_info = !nvidia-smi\n",
    "        gpu_info = \"\\n\".join(gpu_info)\n",
    "        print(\"GPU Information:\")\n",
    "        print(gpu_info)\n",
    "    except:\n",
    "        print(\"GPU information not available\")\n",
    "\n",
    "    try:\n",
    "        import multiprocessing\n",
    "\n",
    "        cpu_info = f\"Number of CPU cores: {multiprocessing.cpu_count()}\"\n",
    "        print(\"\\nCPU Information:\")\n",
    "        print(cpu_info)\n",
    "    except:\n",
    "        print(\"CPU information not available\")\n",
    "else:\n",
    "    print(\"Not running in Colab.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81952a1-af98-4fe5-9849-3f94ec1b78ea",
   "metadata": {},
   "source": [
    "## Build model\n",
    "\n",
    "Crack branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b43afd-1055-48b9-9b0d-0597354fb0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_particle_coordinates(dx, n_div_x, n_div_y):\n",
    "    particle_coordinates = np.zeros([n_div_x * n_div_y, 2])\n",
    "    counter = 0\n",
    "\n",
    "    for i_y in range(n_div_y):  # depth\n",
    "        for i_x in range(n_div_x):  # length\n",
    "            coord_x = dx * i_x\n",
    "            coord_y = dx * i_y\n",
    "            particle_coordinates[counter, 0] = coord_x\n",
    "            particle_coordinates[counter, 1] = coord_y\n",
    "            counter += 1\n",
    "\n",
    "    return particle_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc934906-3cfd-4abb-bf21-23cf16d7fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_boundary_conditions(particles, dx):\n",
    "    bc_flag = np.zeros((len(particles), 2), dtype=np.intc)\n",
    "    bc_unit_vector = np.zeros((len(particles), 2), dtype=np.intc)\n",
    "\n",
    "    tol = 1e-6\n",
    "\n",
    "    for i, particle in enumerate(particles):\n",
    "        if particle[1] < (0.02 + tol):\n",
    "            bc_flag[i, 1] = 1\n",
    "            bc_unit_vector[i, 1] = -1\n",
    "        if particle[1] > (0.18 - dx - tol):\n",
    "            bc_flag[i, 1] = 1\n",
    "            bc_unit_vector[i, 1] = 1\n",
    "\n",
    "    return bc_flag, bc_unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac3e790c-8525-4587-9af9-db6406afeba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 1e-3\n",
    "n_div_x = np.rint(0.4 / dx).astype(int)\n",
    "n_div_y = np.rint(0.2 / dx).astype(int)\n",
    "notch = [np.array([0 - dx, 0.1 - (dx / 2)]), np.array([0.2, 0.1 - (dx / 2)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f833372-351c-49dc-ac61-943b50733a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = build_particle_coordinates(dx, n_div_x, n_div_y)\n",
    "flag, unit_vector = build_boundary_conditions(x, dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6fd3768-72ab-43ef-adc5-2f83883a9809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markhobbs/Documents/02-repositories/pypd/pypd/tools.py:93: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  alpha = alpha_numerator / denominator\n",
      "/Users/markhobbs/Documents/02-repositories/pypd/pypd/tools.py:94: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  beta = beta_numerator / denominator\n"
     ]
    }
   ],
   "source": [
    "material = pypd.Material(name=\"homalite\", E=4.55e9, Gf=38.46, density=1230, ft=2.5)\n",
    "bc = pypd.BoundaryConditions(flag, unit_vector, magnitude=1e-4)\n",
    "particles = pypd.ParticleSet(x, dx, bc, material)\n",
    "bonds = pypd.BondSet(particles, influence=pypd.Constant, notch=notch)\n",
    "model = pypd.Model(particles, bonds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f6534-6d83-4db3-87a0-6da88dd382b5",
   "metadata": {},
   "source": [
    "## Speed testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1673fdd2-687d-46a7-846f-e74005033ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeit\n",
    "def compute_nodal_forces_a(\n",
    "    x,\n",
    "    u,\n",
    "    cell_volume,\n",
    "    bondlist,\n",
    "    d,\n",
    "    c,\n",
    "    f_x,\n",
    "    f_y,\n",
    "    material_law,\n",
    "    surface_correction_factors,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute particle forces - employs bondlist\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bondlist : ndarray (int)\n",
    "        Array of pairwise interactions (bond list)\n",
    "\n",
    "    x : ndarray (float)\n",
    "        Material point coordinates in the reference configuration\n",
    "\n",
    "    u : ndarray (float)\n",
    "        Nodal displacement\n",
    "\n",
    "    d : ndarray (float)\n",
    "        Bond damage (softening parameter). The value of d will range from 0\n",
    "        to 1, where 0 indicates that the bond is still in the elastic range,\n",
    "        and 1 represents a bond that has failed\n",
    "\n",
    "    c : float\n",
    "        Bond stiffness\n",
    "\n",
    "    material_law : function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    node_force : ndarray (float)\n",
    "        Nodal force array\n",
    "\n",
    "    d : ndarray (float)\n",
    "        Bond damage (softening parameter). The value of d will range from 0\n",
    "        to 1, where 0 indicates that the bond is still in the elastic range,\n",
    "        and 1 represents a bond that has failed\n",
    "    \"\"\"\n",
    "\n",
    "    n_nodes = np.shape(x)[0]\n",
    "    n_dimensions = np.shape(x)[1]\n",
    "    n_bonds = np.shape(bondlist)[0]\n",
    "    node_force = np.zeros((n_nodes, n_dimensions))\n",
    "\n",
    "    for k_bond in range(n_bonds):\n",
    "        node_i = bondlist[k_bond, 0]\n",
    "        node_j = bondlist[k_bond, 1]\n",
    "\n",
    "        xi_x = x[node_j, 0] - x[node_i, 0]\n",
    "        xi_y = x[node_j, 1] - x[node_i, 1]\n",
    "\n",
    "        xi_eta_x = xi_x + (u[node_j, 0] - u[node_i, 0])\n",
    "        xi_eta_y = xi_y + (u[node_j, 1] - u[node_i, 1])\n",
    "\n",
    "        xi = np.sqrt(xi_x**2 + xi_y**2)\n",
    "        y = np.sqrt(xi_eta_x**2 + xi_eta_y**2)\n",
    "        stretch = (y - xi) / xi\n",
    "\n",
    "        d[k_bond] = material_law(k_bond, stretch, d[k_bond])\n",
    "\n",
    "        f = (\n",
    "            stretch\n",
    "            * c[k_bond]\n",
    "            * (1 - d[k_bond])\n",
    "            * cell_volume\n",
    "            * surface_correction_factors[k_bond]\n",
    "        )\n",
    "        f_x[k_bond] = f * xi_eta_x / y\n",
    "        f_y[k_bond] = f * xi_eta_y / y\n",
    "\n",
    "    # Reduce bond forces to particle forces\n",
    "    for k_bond in range(n_bonds):\n",
    "        node_i = bondlist[k_bond, 0]\n",
    "        node_j = bondlist[k_bond, 1]\n",
    "\n",
    "        node_force[node_i, 0] += f_x[k_bond]\n",
    "        node_force[node_j, 0] -= f_x[k_bond]\n",
    "        node_force[node_i, 1] += f_y[k_bond]\n",
    "        node_force[node_j, 1] -= f_y[k_bond]\n",
    "\n",
    "    return node_force, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e28b9b9-60ce-4d60-bece-5519da3ae1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "\n",
    "@timeit\n",
    "@njit(parallel=True, fastmath=True)\n",
    "def compute_nodal_forces_b(\n",
    "    x,\n",
    "    u,\n",
    "    cell_volume,\n",
    "    bondlist,\n",
    "    d,\n",
    "    c,\n",
    "    f_x,\n",
    "    f_y,\n",
    "    material_law,\n",
    "    surface_correction_factors,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute particle forces - employs bondlist\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bondlist : ndarray (int)\n",
    "        Array of pairwise interactions (bond list)\n",
    "\n",
    "    x : ndarray (float)\n",
    "        Material point coordinates in the reference configuration\n",
    "\n",
    "    u : ndarray (float)\n",
    "        Nodal displacement\n",
    "\n",
    "    d : ndarray (float)\n",
    "        Bond damage (softening parameter). The value of d will range from 0\n",
    "        to 1, where 0 indicates that the bond is still in the elastic range,\n",
    "        and 1 represents a bond that has failed\n",
    "\n",
    "    c : float\n",
    "        Bond stiffness\n",
    "\n",
    "    material_law : function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    node_force : ndarray (float)\n",
    "        Nodal force array\n",
    "\n",
    "    d : ndarray (float)\n",
    "        Bond damage (softening parameter). The value of d will range from 0\n",
    "        to 1, where 0 indicates that the bond is still in the elastic range,\n",
    "        and 1 represents a bond that has failed\n",
    "    \"\"\"\n",
    "\n",
    "    n_nodes = np.shape(x)[0]\n",
    "    n_dimensions = np.shape(x)[1]\n",
    "    n_bonds = np.shape(bondlist)[0]\n",
    "    node_force = np.zeros((n_nodes, n_dimensions))\n",
    "\n",
    "    for k_bond in prange(n_bonds):\n",
    "        node_i = bondlist[k_bond, 0]\n",
    "        node_j = bondlist[k_bond, 1]\n",
    "\n",
    "        xi_x = x[node_j, 0] - x[node_i, 0]\n",
    "        xi_y = x[node_j, 1] - x[node_i, 1]\n",
    "\n",
    "        xi_eta_x = xi_x + (u[node_j, 0] - u[node_i, 0])\n",
    "        xi_eta_y = xi_y + (u[node_j, 1] - u[node_i, 1])\n",
    "\n",
    "        xi = np.sqrt(xi_x**2 + xi_y**2)\n",
    "        y = np.sqrt(xi_eta_x**2 + xi_eta_y**2)\n",
    "        stretch = (y - xi) / xi\n",
    "\n",
    "        d[k_bond] = material_law(k_bond, stretch, d[k_bond])\n",
    "\n",
    "        f = (\n",
    "            stretch\n",
    "            * c[k_bond]\n",
    "            * (1 - d[k_bond])\n",
    "            * cell_volume\n",
    "            * surface_correction_factors[k_bond]\n",
    "        )\n",
    "        f_x[k_bond] = f * xi_eta_x / y\n",
    "        f_y[k_bond] = f * xi_eta_y / y\n",
    "\n",
    "    # Reduce bond forces to particle forces\n",
    "    for k_bond in range(n_bonds):\n",
    "        node_i = bondlist[k_bond, 0]\n",
    "        node_j = bondlist[k_bond, 1]\n",
    "\n",
    "        node_force[node_i, 0] += f_x[k_bond]\n",
    "        node_force[node_j, 0] -= f_x[k_bond]\n",
    "        node_force[node_i, 1] += f_y[k_bond]\n",
    "        node_force[node_j, 1] -= f_y[k_bond]\n",
    "\n",
    "    return node_force, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3da945c-4dbd-4aa7-9645-a59acefb513f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'compute_nodal_forces_a' executed in 3.8570 seconds\n",
      "Function 'compute_nodal_forces_b' executed in 0.0052 seconds\n"
     ]
    }
   ],
   "source": [
    "compute_nodal_forces_a(particles.x, \n",
    "                       particles.u, \n",
    "                       particles.cell_volume,\n",
    "                       bonds.bondlist, \n",
    "                       bonds.d, \n",
    "                       bonds.c, \n",
    "                       bonds.f_x,\n",
    "                       bonds.f_y,\n",
    "                       bonds.constitutive_law.calculate_bond_damage, \n",
    "                       bonds.surface_correction_factors);\n",
    "\n",
    "compute_nodal_forces_b(particles.x, \n",
    "                       particles.u, \n",
    "                       particles.cell_volume,\n",
    "                       bonds.bondlist, \n",
    "                       bonds.d, \n",
    "                       bonds.c, \n",
    "                       bonds.f_x,\n",
    "                       bonds.f_y,\n",
    "                       bonds.constitutive_law.calculate_bond_damage, \n",
    "                       bonds.surface_correction_factors);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3029dc29-2994-430b-bc93-2591c31707fc",
   "metadata": {},
   "source": [
    "## Numba CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4f62c41-815f-4a5c-9c87-f281db3eb7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "\n",
    "print(cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ff9e510-99da-4f74-866b-a36787d8d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cuda_device_info(verbose=True):\n",
    "    \"\"\"\n",
    "    Retrieve comprehensive information about the current CUDA device.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    verbose : bool, optional\n",
    "        If True, print device information. If False, return as dictionary.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict or None\n",
    "        Dictionary of device properties if verbose=False, otherwise None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get current device\n",
    "        device = cuda.get_current_device()\n",
    "        context = cuda.current_context()\n",
    "        \n",
    "        # Collect device information\n",
    "        device_info = {\n",
    "            \"name\": device.name,\n",
    "            \"compute_capability\": device.compute_capability,\n",
    "            \n",
    "            # Memory information\n",
    "            \"total_memory_gb\": context.get_memory_info().total / 1e9,\n",
    "            \"free_memory_gb\": context.get_memory_info().free / 1e9,\n",
    "            \n",
    "            # Compute resources\n",
    "            \"multiprocessors\": device.MULTIPROCESSOR_COUNT,\n",
    "            \"max_threads_per_block\": device.MAX_THREADS_PER_BLOCK,\n",
    "            \n",
    "            # Grid and block limitations\n",
    "            \"max_grid_dimensions\": {\n",
    "                \"x\": device.MAX_GRID_DIM_X,\n",
    "                \"y\": device.MAX_GRID_DIM_Y,\n",
    "                \"z\": device.MAX_GRID_DIM_Z\n",
    "            },\n",
    "            \n",
    "            # Detailed performance characteristics\n",
    "            \"warp_size\": device.WARP_SIZE,\n",
    "            \"clock_rate_khz\": device.CLOCK_RATE,\n",
    "            \"memory_clock_rate_khz\": device.MEMORY_CLOCK_RATE,\n",
    "        }\n",
    "        \n",
    "        # Formatted printing if verbose\n",
    "        if verbose:\n",
    "            print(\"CUDA Device Information:\")\n",
    "            print(\"-\" * 40)\n",
    "            print(f\"{'Device Name:':<25} {device_info['name']}\")\n",
    "            print(f\"{'Compute Capability:':<25} {device_info['compute_capability']}\")\n",
    "            \n",
    "            print(\"\\nMemory:\")\n",
    "            print(f\"{'Total Memory:':<25} {device_info['total_memory_gb']:.2f} GB\")\n",
    "            print(f\"{'Free Memory:':<25} {device_info['free_memory_gb']:.2f} GB\")\n",
    "            \n",
    "            print(\"\\nCompute Resources:\")\n",
    "            print(f\"{'Multiprocessors:':<25} {device_info['multiprocessors']}\")\n",
    "            print(f\"{'Max Threads per Block:':<25} {device_info['max_threads_per_block']}\")\n",
    "            \n",
    "            print(\"\\nGrid Limitations:\")\n",
    "            print(f\"{'Max Grid Dimensions X:':<25} {device_info['max_grid_dimensions']['x']}\")\n",
    "            print(f\"{'Max Grid Dimensions Y:':<25} {device_info['max_grid_dimensions']['y']}\")\n",
    "            print(f\"{'Max Grid Dimensions Z:':<25} {device_info['max_grid_dimensions']['z']}\")\n",
    "            \n",
    "            print(\"\\nAdditional Characteristics:\")\n",
    "            print(f\"{'Warp Size:':<25} {device_info['warp_size']}\")\n",
    "            print(f\"{'Clock Rate:':<25} {device_info['clock_rate_khz']/1e6:.2f} GHz\")\n",
    "            print(f\"{'Memory Clock Rate:':<25} {device_info['memory_clock_rate_khz']/1e6:.2f} GHz\")\n",
    "            \n",
    "            print(\"\\nEstimated Parallel Computation Capacity:\")\n",
    "            max_blocks_per_mp = device_info['max_grid_dimensions']['x']\n",
    "            total_max_blocks = max_blocks_per_mp * device_info['multiprocessors']\n",
    "            print(f\"{'Max Blocks per Multiprocessor:':<25} {max_blocks_per_mp}\")\n",
    "            print(f\"{'Total Potential Parallel Blocks:':<25} {total_max_blocks}\")\n",
    "        \n",
    "        return device_info if not verbose else None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving CUDA device information: {e}\")\n",
    "        return None\n",
    "\n",
    "def estimate_optimal_launch_configuration(total_work_items, max_threads_per_block=None):\n",
    "    \"\"\"\n",
    "    Estimate optimal CUDA kernel launch configuration\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    total_work_items : int\n",
    "        Total number of work items to process\n",
    "    max_threads_per_block : int, optional\n",
    "        Maximum threads per block (defaults to device maximum)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (threads_per_block, blocks_per_grid)\n",
    "    \"\"\"\n",
    "    # Get device info if not provided\n",
    "    device = cuda.get_current_device()\n",
    "    \n",
    "    # Use device max if not specified\n",
    "    if max_threads_per_block is None:\n",
    "        max_threads_per_block = device.MAX_THREADS_PER_BLOCK\n",
    "    \n",
    "    # Standard warp size (typically 32)\n",
    "    warp_size = device.WARP_SIZE\n",
    "    \n",
    "    # Round threads per block to nearest multiple of warp size\n",
    "    threads_per_block = min(\n",
    "        max_threads_per_block, \n",
    "        ((total_work_items + warp_size - 1) // warp_size) * warp_size\n",
    "    )\n",
    "    \n",
    "    # Calculate blocks, ensuring we don't exceed grid dimension limits\n",
    "    blocks_per_grid = (total_work_items + threads_per_block - 1) // threads_per_block\n",
    "    \n",
    "    # Respect max grid dimension\n",
    "    blocks_per_grid = min(blocks_per_grid, device.MAX_GRID_DIM_X)\n",
    "    \n",
    "    return threads_per_block, blocks_per_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34ae448d-312d-4077-96e0-0d5383af5b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving CUDA device information: Error at driver init: \n",
      "\n",
      "CUDA driver library cannot be found.\n",
      "If you are sure that a CUDA driver is installed,\n",
      "try setting environment variable NUMBA_CUDA_DRIVER\n",
      "with the file path of the CUDA driver shared library.\n",
      ":\n",
      "\n",
      "Launch Configuration Estimation:\n"
     ]
    },
    {
     "ename": "CudaSupportError",
     "evalue": "Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCudaSupportError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLaunch Configuration Estimation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m total_work_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1_000_000\u001b[39m\n\u001b[0;32m----> 5\u001b[0m threads, blocks \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_optimal_launch_configuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_work_items\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_work_items\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m work items:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThreads per Block: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthreads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 100\u001b[0m, in \u001b[0;36mestimate_optimal_launch_configuration\u001b[0;34m(total_work_items, max_threads_per_block)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03mEstimate optimal CUDA kernel launch configuration\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m    (threads_per_block, blocks_per_grid)\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Get device info if not provided\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_current_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Use device max if not specified\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_threads_per_block \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/pypd-EEdp8jsB/lib/python3.11/site-packages/numba/cuda/api.py:443\u001b[0m, in \u001b[0;36mget_current_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_current_device\u001b[39m():\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet current device associated with the current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcurrent_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/pypd-EEdp8jsB/lib/python3.11/site-packages/numba/cuda/cudadrv/devices.py:220\u001b[0m, in \u001b[0;36mget_context\u001b[0;34m(devnum)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_context\u001b[39m(devnum\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the current device or use a device by device number, and\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    return the CUDA context.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_runtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevnum\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/pypd-EEdp8jsB/lib/python3.11/site-packages/numba/cuda/cudadrv/devices.py:138\u001b[0m, in \u001b[0;36m_Runtime.get_or_create_context\u001b[0;34m(self, devnum)\u001b[0m\n\u001b[1;32m    136\u001b[0m attached_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_attached_context()\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attached_ctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_or_create_context_uncached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevnum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attached_ctx\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/pypd-EEdp8jsB/lib/python3.11/site-packages/numba/cuda/cudadrv/devices.py:153\u001b[0m, in \u001b[0;36m_Runtime._get_or_create_context_uncached\u001b[0;34m(self, devnum)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See also ``get_or_create_context(devnum)``.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03mThis version does not read the cache.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# Try to get the active context in the CUDA stack or\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# activate GPU-0 with the primary context\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_active_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mac\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mac\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_activate_context_for\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/pypd-EEdp8jsB/lib/python3.11/site-packages/numba/cuda/cudadrv/driver.py:495\u001b[0m, in \u001b[0;36m_ActiveContext.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m     hctx \u001b[38;5;241m=\u001b[39m drvapi\u001b[38;5;241m.\u001b[39mcu_context(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 495\u001b[0m     \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuCtxGetCurrent\u001b[49m(byref(hctx))\n\u001b[1;32m    496\u001b[0m     hctx \u001b[38;5;241m=\u001b[39m hctx \u001b[38;5;28;01mif\u001b[39;00m hctx\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/pypd-EEdp8jsB/lib/python3.11/site-packages/numba/cuda/cudadrv/driver.py:295\u001b[0m, in \u001b[0;36mDriver.__getattr__\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialization_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CudaSupportError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError at driver init: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    296\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialization_error)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m USE_NV_BINDING:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cuda_python_wrap_fn(fname)\n",
      "\u001b[0;31mCudaSupportError\u001b[0m: Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:"
     ]
    }
   ],
   "source": [
    "get_cuda_device_info()\n",
    "\n",
    "print(\"\\nLaunch Configuration Estimation:\")\n",
    "total_work_items = 1_000_000\n",
    "threads, blocks = estimate_optimal_launch_configuration(total_work_items)\n",
    "print(f\"For {total_work_items} work items:\")\n",
    "print(f\"Threads per Block: {threads}\")\n",
    "print(f\"Blocks per Grid: {blocks}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
