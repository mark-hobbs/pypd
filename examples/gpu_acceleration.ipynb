{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fa3f694-ca6c-47d9-8f97-3f7f44274974",
   "metadata": {},
   "source": [
    "# GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ffda115-a162-4e96-97d8-9c9ef0ebcd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ec94f4-ba7d-4b56-940e-3270d57975f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"Function '{func.__name__}' executed in {end - start:.4f} seconds\")\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78623c73-e4ee-43ca-8eb9-62d2dbdf87d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in Colab\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "    !pip install git+https://github.com/mark-hobbs/pypd.git@feature/gpu\n",
    "    print(\"Package installed successfully\")\n",
    "    import pypd\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    import pypd\n",
    "\n",
    "    print(\"Not running in Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e3e419f-a756-4b07-bc85-702c907dea98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in Colab.\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "    try:\n",
    "        gpu_info = !nvidia-smi\n",
    "        gpu_info = \"\\n\".join(gpu_info)\n",
    "        print(\"GPU Information:\")\n",
    "        print(gpu_info)\n",
    "    except:\n",
    "        print(\"GPU information not available\")\n",
    "\n",
    "    try:\n",
    "        import multiprocessing\n",
    "\n",
    "        cpu_info = f\"Number of CPU cores: {multiprocessing.cpu_count()}\"\n",
    "        print(\"\\nCPU Information:\")\n",
    "        print(cpu_info)\n",
    "    except:\n",
    "        print(\"CPU information not available\")\n",
    "else:\n",
    "    print(\"Not running in Colab.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81952a1-af98-4fe5-9849-3f94ec1b78ea",
   "metadata": {},
   "source": [
    "## Build model\n",
    "\n",
    "Crack branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b43afd-1055-48b9-9b0d-0597354fb0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_particle_coordinates(dx, n_div_x, n_div_y):\n",
    "    particle_coordinates = np.zeros([n_div_x * n_div_y, 2])\n",
    "    counter = 0\n",
    "\n",
    "    for i_y in range(n_div_y):  # depth\n",
    "        for i_x in range(n_div_x):  # length\n",
    "            coord_x = dx * i_x\n",
    "            coord_y = dx * i_y\n",
    "            particle_coordinates[counter, 0] = coord_x\n",
    "            particle_coordinates[counter, 1] = coord_y\n",
    "            counter += 1\n",
    "\n",
    "    return particle_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc934906-3cfd-4abb-bf21-23cf16d7fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_boundary_conditions(particles, dx):\n",
    "    bc_flag = np.zeros((len(particles), 2), dtype=np.intc)\n",
    "    bc_unit_vector = np.zeros((len(particles), 2), dtype=np.intc)\n",
    "\n",
    "    tol = 1e-6\n",
    "\n",
    "    for i, particle in enumerate(particles):\n",
    "        if particle[1] < (0.02 + tol):\n",
    "            bc_flag[i, 1] = 1\n",
    "            bc_unit_vector[i, 1] = -1\n",
    "        if particle[1] > (0.18 - dx - tol):\n",
    "            bc_flag[i, 1] = 1\n",
    "            bc_unit_vector[i, 1] = 1\n",
    "\n",
    "    return bc_flag, bc_unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac3e790c-8525-4587-9af9-db6406afeba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 1e-3\n",
    "n_div_x = np.rint(0.4 / dx).astype(int)\n",
    "n_div_y = np.rint(0.2 / dx).astype(int)\n",
    "notch = [np.array([0 - dx, 0.1 - (dx / 2)]), np.array([0.2, 0.1 - (dx / 2)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f833372-351c-49dc-ac61-943b50733a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = build_particle_coordinates(dx, n_div_x, n_div_y)\n",
    "flag, unit_vector = build_boundary_conditions(x, dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6fd3768-72ab-43ef-adc5-2f83883a9809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markhobbs/Documents/02-repositories/pypd/pypd/tools.py:93: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  alpha = alpha_numerator / denominator\n",
      "/Users/markhobbs/Documents/02-repositories/pypd/pypd/tools.py:94: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  beta = beta_numerator / denominator\n"
     ]
    }
   ],
   "source": [
    "material = pypd.Material(name=\"homalite\", E=4.55e9, Gf=38.46, density=1230, ft=2.5)\n",
    "bc = pypd.BoundaryConditions(flag, unit_vector, magnitude=1e-4)\n",
    "particles = pypd.ParticleSet(x, dx, bc, material)\n",
    "bonds = pypd.BondSet(particles, influence=pypd.Constant, notch=notch)\n",
    "model = pypd.Model(particles, bonds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bec3a70-2e48-4baa-9d52-549f8c3a6a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "simulation = pypd.Simulation(n_time_steps=5000, damping=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f6534-6d83-4db3-87a0-6da88dd382b5",
   "metadata": {},
   "source": [
    "## Speed testing: particle forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1673fdd2-687d-46a7-846f-e74005033ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeit\n",
    "def compute_nodal_forces_a(\n",
    "    x,\n",
    "    u,\n",
    "    cell_volume,\n",
    "    bondlist,\n",
    "    d,\n",
    "    c,\n",
    "    f_x,\n",
    "    f_y,\n",
    "    material_law,\n",
    "    surface_correction_factors,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute particle forces - employs bondlist\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bondlist : ndarray (int)\n",
    "        Array of pairwise interactions (bond list)\n",
    "\n",
    "    x : ndarray (float)\n",
    "        Material point coordinates in the reference configuration\n",
    "\n",
    "    u : ndarray (float)\n",
    "        Nodal displacement\n",
    "\n",
    "    d : ndarray (float)\n",
    "        Bond damage (softening parameter). The value of d will range from 0\n",
    "        to 1, where 0 indicates that the bond is still in the elastic range,\n",
    "        and 1 represents a bond that has failed\n",
    "\n",
    "    c : float\n",
    "        Bond stiffness\n",
    "\n",
    "    material_law : function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    node_force : ndarray (float)\n",
    "        Nodal force array\n",
    "\n",
    "    d : ndarray (float)\n",
    "        Bond damage (softening parameter). The value of d will range from 0\n",
    "        to 1, where 0 indicates that the bond is still in the elastic range,\n",
    "        and 1 represents a bond that has failed\n",
    "    \"\"\"\n",
    "\n",
    "    n_nodes = np.shape(x)[0]\n",
    "    n_dimensions = np.shape(x)[1]\n",
    "    n_bonds = np.shape(bondlist)[0]\n",
    "    node_force = np.zeros((n_nodes, n_dimensions))\n",
    "\n",
    "    for k_bond in range(n_bonds):\n",
    "        node_i = bondlist[k_bond, 0]\n",
    "        node_j = bondlist[k_bond, 1]\n",
    "\n",
    "        xi_x = x[node_j, 0] - x[node_i, 0]\n",
    "        xi_y = x[node_j, 1] - x[node_i, 1]\n",
    "\n",
    "        xi_eta_x = xi_x + (u[node_j, 0] - u[node_i, 0])\n",
    "        xi_eta_y = xi_y + (u[node_j, 1] - u[node_i, 1])\n",
    "\n",
    "        xi = np.sqrt(xi_x**2 + xi_y**2)\n",
    "        y = np.sqrt(xi_eta_x**2 + xi_eta_y**2)\n",
    "        stretch = (y - xi) / xi\n",
    "\n",
    "        d[k_bond] = material_law(k_bond, stretch, d[k_bond])\n",
    "\n",
    "        f = (\n",
    "            stretch\n",
    "            * c[k_bond]\n",
    "            * (1 - d[k_bond])\n",
    "            * cell_volume\n",
    "            * surface_correction_factors[k_bond]\n",
    "        )\n",
    "        f_x[k_bond] = f * xi_eta_x / y\n",
    "        f_y[k_bond] = f * xi_eta_y / y\n",
    "\n",
    "    # Reduce bond forces to particle forces\n",
    "    for k_bond in range(n_bonds):\n",
    "        node_i = bondlist[k_bond, 0]\n",
    "        node_j = bondlist[k_bond, 1]\n",
    "\n",
    "        node_force[node_i, 0] += f_x[k_bond]\n",
    "        node_force[node_j, 0] -= f_x[k_bond]\n",
    "        node_force[node_i, 1] += f_y[k_bond]\n",
    "        node_force[node_j, 1] -= f_y[k_bond]\n",
    "\n",
    "    return node_force, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e28b9b9-60ce-4d60-bece-5519da3ae1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "\n",
    "@timeit\n",
    "@njit(parallel=True, fastmath=True)\n",
    "def compute_nodal_forces_b(\n",
    "    x,\n",
    "    u,\n",
    "    cell_volume,\n",
    "    bondlist,\n",
    "    d,\n",
    "    c,\n",
    "    f_x,\n",
    "    f_y,\n",
    "    material_law,\n",
    "    surface_correction_factors,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute particle forces - employs bondlist\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bondlist : ndarray (int)\n",
    "        Array of pairwise interactions (bond list)\n",
    "\n",
    "    x : ndarray (float)\n",
    "        Material point coordinates in the reference configuration\n",
    "\n",
    "    u : ndarray (float)\n",
    "        Nodal displacement\n",
    "\n",
    "    d : ndarray (float)\n",
    "        Bond damage (softening parameter). The value of d will range from 0\n",
    "        to 1, where 0 indicates that the bond is still in the elastic range,\n",
    "        and 1 represents a bond that has failed\n",
    "\n",
    "    c : float\n",
    "        Bond stiffness\n",
    "\n",
    "    material_law : function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    node_force : ndarray (float)\n",
    "        Nodal force array\n",
    "\n",
    "    d : ndarray (float)\n",
    "        Bond damage (softening parameter). The value of d will range from 0\n",
    "        to 1, where 0 indicates that the bond is still in the elastic range,\n",
    "        and 1 represents a bond that has failed\n",
    "    \"\"\"\n",
    "\n",
    "    n_nodes = np.shape(x)[0]\n",
    "    n_dimensions = np.shape(x)[1]\n",
    "    n_bonds = np.shape(bondlist)[0]\n",
    "    node_force = np.zeros((n_nodes, n_dimensions))\n",
    "\n",
    "    for k_bond in prange(n_bonds):\n",
    "        node_i = bondlist[k_bond, 0]\n",
    "        node_j = bondlist[k_bond, 1]\n",
    "\n",
    "        xi_x = x[node_j, 0] - x[node_i, 0]\n",
    "        xi_y = x[node_j, 1] - x[node_i, 1]\n",
    "\n",
    "        xi_eta_x = xi_x + (u[node_j, 0] - u[node_i, 0])\n",
    "        xi_eta_y = xi_y + (u[node_j, 1] - u[node_i, 1])\n",
    "\n",
    "        xi = np.sqrt(xi_x**2 + xi_y**2)\n",
    "        y = np.sqrt(xi_eta_x**2 + xi_eta_y**2)\n",
    "        stretch = (y - xi) / xi\n",
    "\n",
    "        d[k_bond] = material_law(k_bond, stretch, d[k_bond])\n",
    "\n",
    "        f = (\n",
    "            stretch\n",
    "            * c[k_bond]\n",
    "            * (1 - d[k_bond])\n",
    "            * cell_volume\n",
    "            * surface_correction_factors[k_bond]\n",
    "        )\n",
    "        f_x[k_bond] = f * xi_eta_x / y\n",
    "        f_y[k_bond] = f * xi_eta_y / y\n",
    "\n",
    "    # Reduce bond forces to particle forces\n",
    "    for k_bond in range(n_bonds):\n",
    "        node_i = bondlist[k_bond, 0]\n",
    "        node_j = bondlist[k_bond, 1]\n",
    "\n",
    "        node_force[node_i, 0] += f_x[k_bond]\n",
    "        node_force[node_j, 0] -= f_x[k_bond]\n",
    "        node_force[node_i, 1] += f_y[k_bond]\n",
    "        node_force[node_j, 1] -= f_y[k_bond]\n",
    "\n",
    "    return node_force, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3da945c-4dbd-4aa7-9645-a59acefb513f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'compute_nodal_forces_a' executed in 3.7449 seconds\n",
      "Function 'compute_nodal_forces_b' executed in 0.0060 seconds\n"
     ]
    }
   ],
   "source": [
    "compute_nodal_forces_a(particles.x, \n",
    "                       particles.u, \n",
    "                       particles.cell_volume,\n",
    "                       bonds.bondlist, \n",
    "                       bonds.d, \n",
    "                       bonds.c, \n",
    "                       bonds.f_x,\n",
    "                       bonds.f_y,\n",
    "                       bonds.constitutive_law.calculate_bond_damage, \n",
    "                       bonds.surface_correction_factors);\n",
    "\n",
    "compute_nodal_forces_b(particles.x, \n",
    "                       particles.u, \n",
    "                       particles.cell_volume,\n",
    "                       bonds.bondlist, \n",
    "                       bonds.d, \n",
    "                       bonds.c, \n",
    "                       bonds.f_x,\n",
    "                       bonds.f_y,\n",
    "                       bonds.constitutive_law.calculate_bond_damage, \n",
    "                       bonds.surface_correction_factors);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a93d0-e7f3-4057-b835-c47c7e11a974",
   "metadata": {},
   "source": [
    "## Speed testing: update particle positions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2704b23e-b681-4a3b-8387-d5b932eeb411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@timeit\n",
    "def euler_cromer_a(\n",
    "    node_force,\n",
    "    u,\n",
    "    v,\n",
    "    a,\n",
    "    damping,\n",
    "    node_density,\n",
    "    dt,\n",
    "    bc_flag,\n",
    "    bc_magnitude,\n",
    "    bc_unit_vector,\n",
    "):\n",
    "    \"\"\"\n",
    "    Update particle positions using an Euler-Cromer time integration scheme\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    u : ndarray (float)\n",
    "        Particle displacement\n",
    "\n",
    "    v : ndarray (float)\n",
    "        Particle velocity\n",
    "\n",
    "    a : ndarray (float)\n",
    "        Particle acceleration\n",
    "    \"\"\"\n",
    "\n",
    "    n_nodes = np.shape(node_force)[0]\n",
    "    n_dimensions = np.shape(node_force)[1]\n",
    "\n",
    "    for node_i in range(n_nodes):\n",
    "        for dof in range(n_dimensions):\n",
    "            a[node_i, dof] = (\n",
    "                node_force[node_i, dof] - damping * v[node_i, dof]\n",
    "            ) / node_density\n",
    "            v[node_i, dof] = v[node_i, dof] + (a[node_i, dof] * dt)\n",
    "            u[node_i, dof] = u[node_i, dof] + (v[node_i, dof] * dt)\n",
    "\n",
    "            if bc_flag[node_i, dof] != 0:\n",
    "                u[node_i, dof] = bc_magnitude * bc_unit_vector[node_i, dof]\n",
    "\n",
    "    return u, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "179bcec8-3513-4146-82be-57b06d8f279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "\n",
    "@timeit\n",
    "@njit(parallel=True)\n",
    "def euler_cromer_b(\n",
    "    node_force,\n",
    "    u,\n",
    "    v,\n",
    "    a,\n",
    "    damping,\n",
    "    node_density,\n",
    "    dt,\n",
    "    bc_flag,\n",
    "    bc_magnitude,\n",
    "    bc_unit_vector,\n",
    "):\n",
    "    \"\"\"\n",
    "    Update particle positions using an Euler-Cromer time integration scheme\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    u : ndarray (float)\n",
    "        Particle displacement\n",
    "\n",
    "    v : ndarray (float)\n",
    "        Particle velocity\n",
    "\n",
    "    a : ndarray (float)\n",
    "        Particle acceleration\n",
    "    \"\"\"\n",
    "\n",
    "    n_nodes = np.shape(node_force)[0]\n",
    "    n_dimensions = np.shape(node_force)[1]\n",
    "\n",
    "    for node_i in prange(n_nodes):\n",
    "        for dof in range(n_dimensions):\n",
    "            a[node_i, dof] = (\n",
    "                node_force[node_i, dof] - damping * v[node_i, dof]\n",
    "            ) / node_density\n",
    "            v[node_i, dof] = v[node_i, dof] + (a[node_i, dof] * dt)\n",
    "            u[node_i, dof] = u[node_i, dof] + (v[node_i, dof] * dt)\n",
    "\n",
    "            if bc_flag[node_i, dof] != 0:\n",
    "                u[node_i, dof] = bc_magnitude * bc_unit_vector[node_i, dof]\n",
    "\n",
    "    return u, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3aa1b59b-1eb6-4e4f-9f5c-21b30ea68224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'euler_cromer_a' executed in 0.2812 seconds\n",
      "Function 'euler_cromer_b' executed in 0.0004 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0., -1.],\n",
       "        [ 0., -1.],\n",
       "        [ 0., -1.],\n",
       "        ...,\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.]]),\n",
       " array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        ...,\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euler_cromer_a(\n",
    "    particles.f,\n",
    "    particles.u,\n",
    "    particles.v,\n",
    "    particles.a,\n",
    "    simulation.damping,\n",
    "    particles.node_density,\n",
    "    1,\n",
    "    particles.bc.flag,\n",
    "    1,\n",
    "    particles.bc.unit_vector,\n",
    ")\n",
    "\n",
    "euler_cromer_b(\n",
    "    particles.f,\n",
    "    particles.u,\n",
    "    particles.v,\n",
    "    particles.a,\n",
    "    simulation.damping,\n",
    "    particles.node_density,\n",
    "    1,\n",
    "    particles.bc.flag,\n",
    "    1,\n",
    "    particles.bc.unit_vector,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3029dc29-2994-430b-bc93-2591c31707fc",
   "metadata": {},
   "source": [
    "## Numba CUDA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
